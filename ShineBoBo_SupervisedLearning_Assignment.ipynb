{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9679b0aa",
   "metadata": {},
   "source": [
    "# What is supervised learning?\n",
    "    Supervised learning is traning the data using labeled data(input + correct answer). The model learns from these examples to predict the outcome of the new data. It is like a teacher showing the correct answer during practice.\n",
    "\n",
    "# What is classification?\n",
    "    Classification is a type of supervised learning where the data is sorted into different categories. For example, deciding the incoming email is a spam mail or not. The output of this classification is always a label or class.\n",
    "\n",
    "# What is regression?\n",
    "    Regression is also a type of supervised learning that is used to predict numbers. For example, predicting house pricing based on size, neighbourhood and location. Unlike classification, the output is a continous value, not a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a71ad4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Euclidean): 1.0\n",
      "Accuracy (Manhattan): 1.0\n",
      "Accuracy (Minkowski): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Compare k-NN classifier performance using different distance metrics (Euclidean, Manhattan, Minkowski) on the Iris dataset\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset (features in X, target labels in y)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create k-NN classifiers with different distance metrics\n",
    "knn_euclidean = KNeighborsClassifier(n_neighbors=3, metric='euclidean')   # Euclidean distance\n",
    "knn_manhattan = KNeighborsClassifier(n_neighbors=3, metric='manhattan')   # Manhattan (L1) distance\n",
    "knn_minkowski = KNeighborsClassifier(n_neighbors=3, metric='minkowski', p=3)  # Minkowski distance with p=3\n",
    "\n",
    "# Train (fit) the classifiers on the training data\n",
    "knn_euclidean.fit(X_train, y_train)\n",
    "knn_manhattan.fit(X_train, y_train)\n",
    "knn_minkowski.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set using each classifier\n",
    "y_pred_euclidean = knn_euclidean.predict(X_test)\n",
    "y_pred_manhattan = knn_manhattan.predict(X_test)\n",
    "y_pred_minkowski = knn_minkowski.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy of each model (percentage of correct predictions)\n",
    "accuracy_euclidean = accuracy_score(y_test, y_pred_euclidean)\n",
    "accuracy_manhattan = accuracy_score(y_test, y_pred_manhattan)\n",
    "accuracy_minkowski = accuracy_score(y_test, y_pred_minkowski)\n",
    "\n",
    "# Print the accuracy results for comparison\n",
    "print(\"Accuracy (Euclidean):\", accuracy_euclidean)\n",
    "print(\"Accuracy (Manhattan):\", accuracy_manhattan)\n",
    "print(\"Accuracy (Minkowski):\", accuracy_minkowski)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ef88c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Decision Tree): 1.0\n",
      "Accuracy (Random Forest): 1.0\n",
      "Feature Importances: [0.10509878 0.0212238  0.45005788 0.42361954]\n"
     ]
    }
   ],
   "source": [
    "# Compare Decision Tree and Random Forest classifiers on the Iris dataset and evaluate accuracy + feature importance\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=4, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy scores\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Accuracy (Decision Tree):\", accuracy_dt)\n",
    "print(\"Accuracy (Random Forest):\", accuracy_rf)\n",
    "\n",
    "# Get feature importances from the Random Forest\n",
    "importances = rf.feature_importances_\n",
    "print(\"Feature Importances:\", importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b00b4767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Linear Regression): 0.555891598695242\n",
      "Accuracy (Logistic Regression): 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression and Logistic Regression examples using different datasets\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Linear Regression example using California Housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (Linear Regression):\", mse)\n",
    "\n",
    "# Logistic Regression example with scaling\n",
    "breast_cancer = load_breast_cancer()\n",
    "X, y = breast_cancer.data, breast_cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "logistic = LogisticRegression(max_iter=2000)  # Increase max_iter\n",
    "logistic.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy (Logistic Regression):\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "086d43d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "ROC AUC Score: 1.0\n",
      "Mean Squared Error (MSE): 0.555891598695242\n",
      "Root Mean Squared Error (RMSE): 0.7455813830127748\n",
      "Mean Absolute Error (MAE): 0.533200130495698\n",
      "R-squared: 0.5757877060324526\n"
     ]
    }
   ],
   "source": [
    "# Evaluate various classification and regression metrics using appropriate datasets\n",
    "\n",
    "from sklearn.datasets import load_iris, fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Classification metrics example\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features for logistic regression\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "logistic = LogisticRegression(max_iter=2000)\n",
    "logistic.fit(X_train, y_train)\n",
    "y_pred = logistic.predict(X_test)\n",
    "y_prob = logistic.predict_proba(X_test)[:, 1]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, logistic.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"ROC AUC Score:\", auc)\n",
    "\n",
    "# Regression metrics example using California Housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
